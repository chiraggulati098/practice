{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ece835-aeb7-4ec3-886d-880b9135ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db452b2a-9973-43f0-9758-f544d90f63fe",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed617766-2061-4963-a785-610d46032c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocessing training set\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set/',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969f08f4-7792-4f2b-864b-2ab15963a015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocessing testing set\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set/',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61578b7-bb64-47c5-a320-6b6a969ce46b",
   "metadata": {},
   "source": [
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b960401-6b3e-408a-a2ab-d5734bb1b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the CNN\n",
    "from keras.models import Sequential\n",
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df00aee-da8d-443f-ad18-29f74e2adcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convulation\n",
    "from keras.layers import Conv2D\n",
    "cnn.add(Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c241cb72-1f7d-4413-a118-bb4d6d1e37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling\n",
    "from keras.layers import MaxPool2D\n",
    "cnn.add(MaxPool2D(pool_size=(2,2),strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c661777-4cde-49ae-a6bb-696a5bab77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 2nd convulational layer\n",
    "cnn.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=(2,2),strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49d9147-9757-413b-8591-ade7446ce9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening\n",
    "from keras.layers import Flatten\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f50431d-1e37-458b-a1ff-7ae8ffb28362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full connection\n",
    "from keras.layers import Dense\n",
    "cnn.add(Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546bce82-1706-40de-9508-762a237aaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "cnn.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaead94-3dde-4787-b50f-eea09059eea8",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67eb0c5-34b2-4cf5-8362-0279438ac242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the CNN\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c787d05-0aae-457c-a55c-7d371d7951c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 218s 868ms/step - loss: 0.6569 - accuracy: 0.6112 - val_loss: 0.6778 - val_accuracy: 0.6055\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 28s 114ms/step - loss: 0.6044 - accuracy: 0.6730 - val_loss: 0.5711 - val_accuracy: 0.7210\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.5581 - accuracy: 0.7144 - val_loss: 0.5240 - val_accuracy: 0.7520\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.5180 - accuracy: 0.7450 - val_loss: 0.4957 - val_accuracy: 0.7665\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.4857 - accuracy: 0.7635 - val_loss: 0.5415 - val_accuracy: 0.7255\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.4627 - accuracy: 0.7791 - val_loss: 0.4960 - val_accuracy: 0.7720\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.4481 - accuracy: 0.7911 - val_loss: 0.5036 - val_accuracy: 0.7805\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.4231 - accuracy: 0.8039 - val_loss: 0.5365 - val_accuracy: 0.7490\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.4195 - accuracy: 0.8048 - val_loss: 0.4777 - val_accuracy: 0.7870\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.4049 - accuracy: 0.8184 - val_loss: 0.4736 - val_accuracy: 0.7935\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.3940 - accuracy: 0.8196 - val_loss: 0.4765 - val_accuracy: 0.7945\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.3777 - accuracy: 0.8307 - val_loss: 0.5011 - val_accuracy: 0.7810\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.3653 - accuracy: 0.8393 - val_loss: 0.4819 - val_accuracy: 0.7915\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 29s 114ms/step - loss: 0.3475 - accuracy: 0.8516 - val_loss: 0.4619 - val_accuracy: 0.7870\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.3262 - accuracy: 0.8565 - val_loss: 0.4914 - val_accuracy: 0.7785\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.3071 - accuracy: 0.8687 - val_loss: 0.4838 - val_accuracy: 0.7960\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.3040 - accuracy: 0.8699 - val_loss: 0.4598 - val_accuracy: 0.8005\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.2806 - accuracy: 0.8802 - val_loss: 0.4699 - val_accuracy: 0.8120\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.2682 - accuracy: 0.8871 - val_loss: 0.4886 - val_accuracy: 0.8035\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.2617 - accuracy: 0.8901 - val_loss: 0.5021 - val_accuracy: 0.8075\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.2413 - accuracy: 0.8964 - val_loss: 0.5119 - val_accuracy: 0.8130\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.2301 - accuracy: 0.9069 - val_loss: 0.5118 - val_accuracy: 0.8080\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.2166 - accuracy: 0.9144 - val_loss: 0.5537 - val_accuracy: 0.7945\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.1898 - accuracy: 0.9237 - val_loss: 0.5641 - val_accuracy: 0.8100\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.1912 - accuracy: 0.9220 - val_loss: 0.5763 - val_accuracy: 0.7990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fadc182710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the CNN on Training set and evaluating it on the Test set\n",
    "cnn.fit(x=training_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e702f34-f1b8-4544-a53a-2d7092ab01a3",
   "metadata": {},
   "source": [
    "### Predicting Single Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcdc508-83f4-48b9-ac19-86e85da8ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "418799ae-1b9c-48f5-a805-bc1614a114ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_1 = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg',target_size=(64,64))\n",
    "test_image_2 = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98b84635-9ae4-4540-a461-ddcbbd58a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_1 = image.img_to_array(test_image_1)\n",
    "test_image_2 = image.img_to_array(test_image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75a77b07-2ff8-4776-b8d9-bb7c0bfc8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_1 = np.expand_dims(test_image_1,axis=0)\n",
    "test_image_2 = np.expand_dims(test_image_2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf459ba3-817b-4070-b75b-891103edd16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "result_1 = cnn.predict(test_image_1/255.0)\n",
    "result_2 = cnn.predict(test_image_2/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e47e94ae-2009-43ea-ba3f-149501f85df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f763962-fc58-444e-b1b8-4558e50e7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prediction(l):\n",
    "    if l[0][0] > 0.5:\n",
    "        return 'dog'\n",
    "    else:\n",
    "        return 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "416ca6ce-a97d-4f5a-a36b-4455c6d8a7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3acabf3-e3f3-45ce-bc5e-82331079aac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1ad7c-ca27-4796-9025-0f019de0177f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
